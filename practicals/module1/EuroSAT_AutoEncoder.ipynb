{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0fc4022a",
      "metadata": {
        "id": "0fc4022a"
      },
      "source": [
        "# üõ∞Ô∏è Convolutional Autoencoder (CAE) on EuroSAT RGB Data\n",
        "\n",
        "This notebook shows how to build and train a **Convolutional Autoencoder (CAE)** using PyTorch.\n",
        "We will use the **EuroSAT RGB dataset** and visualize how images can be compressed and reconstructed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726766e4",
      "metadata": {
        "id": "726766e4"
      },
      "outputs": [],
      "source": [
        "import os, zipfile, requests\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5980c6de",
      "metadata": {
        "id": "5980c6de"
      },
      "source": [
        "## 1. Download and Load EuroSAT RGB Data\n",
        "\n",
        "We will download a subset of the dataset (300 images per class) for this lesson."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985c11b0",
      "metadata": {
        "id": "985c11b0"
      },
      "outputs": [],
      "source": [
        "def download_eurosat():\n",
        "    url = \"https://madm.dfki.de/files/sentinel/EuroSAT.zip\"\n",
        "    zip_path = \"EuroSAT.zip\"\n",
        "    target_dir = \"EuroSAT/2750\"\n",
        "\n",
        "    if not os.path.exists(target_dir):\n",
        "        print(\"‚¨áÔ∏è Downloading EuroSAT RGB dataset...\")\n",
        "        response = requests.get(url, stream=True, verify=False)\n",
        "        total = int(response.headers.get('content-length', 0))\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            downloaded = 0\n",
        "            for data in response.iter_content(chunk_size=8192):\n",
        "                f.write(data)\n",
        "                downloaded += len(data)\n",
        "                done = int(50 * downloaded / total)\n",
        "                print(f\"\\r[{'=' * done}{' ' * (50 - done)}] {downloaded/1e6:.1f}/{total/1e6:.1f} MB\", end='')\n",
        "        print(\"\\nüì¶ Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"EuroSAT\")\n",
        "        os.remove(zip_path)\n",
        "        print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n",
        "    else:\n",
        "        print(\"‚úÖ Dataset already available.\")\n",
        "\n",
        "def load_images(data_dir=\"EuroSAT/2750\", max_per_class=300):\n",
        "    images, labels, classes = [], [], []\n",
        "    for class_dir in sorted(Path(data_dir).iterdir()):\n",
        "        if class_dir.is_dir():\n",
        "            cls = class_dir.name\n",
        "            classes.append(cls)\n",
        "            files = list(class_dir.glob(\"*.jpg\"))[:max_per_class]\n",
        "            for f in files:\n",
        "                img = np.array(Image.open(f))\n",
        "                images.append(img)\n",
        "                labels.append(cls)\n",
        "    return np.array(images), np.array(labels), classes\n",
        "\n",
        "# Run download + load\n",
        "download_eurosat()\n",
        "images, true_labels, class_names = load_images(max_per_class=300)\n",
        "print(f\"‚úÖ Loaded {len(images)} images from {len(class_names)} classes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aabccb9",
      "metadata": {
        "id": "7aabccb9"
      },
      "source": [
        "## 2. Preprocessing for PyTorch\n",
        "\n",
        "- Normalize images to [0,1]\n",
        "- Convert to PyTorch tensors\n",
        "- Create a DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71efb5ec",
      "metadata": {
        "id": "71efb5ec"
      },
      "outputs": [],
      "source": [
        "X_tensor = torch.tensor(images / 255.0, dtype=torch.float32).permute(0,3,1,2)  # (N,C,H,W)\n",
        "dataset = TensorDataset(X_tensor, X_tensor)  # Autoencoder: input=target\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "print(f'Dataset shape: {X_tensor.shape}, Number of batches: {len(dataloader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f37bccf",
      "metadata": {
        "id": "3f37bccf"
      },
      "source": [
        "## 3. Build the Convolutional Autoencoder\n",
        "\n",
        "- Encoder compresses images to latent vectors\n",
        "- Decoder reconstructs images from latent vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c808d49",
      "metadata": {
        "id": "1c808d49"
      },
      "outputs": [],
      "source": [
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride=2, padding=1),  # 32x32x32\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # 64x16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # 128x8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*8*8, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128*8*8),\n",
        "            nn.Unflatten(1, (128,8,8)),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out\n",
        "\n",
        "model = ConvAutoencoder(latent_dim=128).to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3601db0a",
      "metadata": {
        "id": "3601db0a"
      },
      "source": [
        "## 4. Train the Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee47719f",
      "metadata": {
        "id": "ee47719f"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "n_epochs = 50\n",
        "for epoch in range(n_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch, _ in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch)\n",
        "        loss = criterion(outputs, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * batch.size(0)\n",
        "    epoch_loss /= len(dataloader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b49f3415",
      "metadata": {
        "id": "b49f3415"
      },
      "source": [
        "## 5. Visualize Reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc506425",
      "metadata": {
        "id": "fc506425"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample_imgs = X_tensor[:10].to(device)\n",
        "    reconstructions = model(sample_imgs).cpu()\n",
        "\n",
        "fig, axes = plt.subplots(2, 10, figsize=(20,4))\n",
        "for i in range(10):\n",
        "    axes[0,i].imshow(sample_imgs[i].permute(1,2,0).cpu())\n",
        "    axes[0,i].axis('off')\n",
        "    axes[0,i].set_title('Original')\n",
        "    axes[1,i].imshow(reconstructions[i].permute(1,2,0))\n",
        "    axes[1,i].axis('off')\n",
        "    axes[1,i].set_title('Reconstructed')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e611e739",
      "metadata": {
        "id": "e611e739"
      },
      "source": [
        "## 6. Why CAEs are Important\n",
        "- **Dimensionality reduction**: Latent vectors can be used for clustering, visualization, or classification.\n",
        "- **Image compression**: Efficiently stores images with minimal quality loss.\n",
        "- **GANs**: Encoders provide meaningful latent spaces for generative models.\n",
        "- **Anomaly detection**: Reconstruction error highlights unusual patterns."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IF8WOKVRi6YU"
      },
      "id": "IF8WOKVRi6YU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}