{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVUDB38pYeBN"
      },
      "source": [
        "# Variational Quantum Classifier on EuroSAT Dataset (Fully Quantum with PCA)\n",
        "\n",
        "This notebook implements a fully quantum variational classifier for Earth Observation data using:\n",
        "- **Dataset**: EuroSAT (satellite imagery classification)\n",
        "- **Dimensionality Reduction**: PCA to compress images to quantum-compatible size\n",
        "- **Framework**: PyTorch Lightning + PennyLane\n",
        "- **Encoding Options**: Angle Encoding vs Amplitude Encoding\n",
        "- **Circuit Options**: Strongly Entangling Layers vs Basic Entangling Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEy0JwrQYeBO"
      },
      "source": [
        "#  COMPLETE NOTEBOOK GUIDE\n",
        "\n",
        "##  What does this notebook do?\n",
        "\n",
        "This notebook implements a **variational quantum classifier** for EuroSAT satellite imagery.\n",
        "\n",
        "### Pipeline:\n",
        "```\n",
        "Satellite Image (64x64x3 RGB)\n",
        "          ↓\n",
        "    PCA (dimensionality reduction)\n",
        "          ↓\n",
        "    8 or 256 features\n",
        "          ↓\n",
        "    Quantum Circuit (encoding + variational layers)\n",
        "          ↓\n",
        "    8 expectation values\n",
        "          ↓\n",
        "    Classical Linear Layer\n",
        "          ↓\n",
        "    10 classes (Annual Crop, Forest, etc.)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "##  Available Configurations\n",
        "\n",
        "### 1. Encoding Type (how to encode data in the quantum circuit):\n",
        "\n",
        "**Angle Encoding** (`encoding='angle'`):\n",
        "- Each feature becomes a rotation angle\n",
        "- 8 qubits = 8 features needed\n",
        "-  Simpler and faster\n",
        "-  Less information for qubit\n",
        "\n",
        "**Amplitude Encoding** (`encoding='amplitude'`):\n",
        "- Features become quantum state amplitudes\n",
        "- 8 qubits = 256 features (2^8)\n",
        "-  More information compresifd\n",
        "-  Requires normalization\n",
        "\n",
        "### 2. Circuit Type (quantum circuit structure):\n",
        "\n",
        "**Strongly Entangling** (`circuit_type='strongly_entangling'`):\n",
        "- Every qubit withnected to all others\n",
        "-  Maximum expressivity\n",
        "-  More parameters to train\n",
        "\n",
        "**Basic Entangling** (`circuit_type='basic_entangling'`):\n",
        "- Only nearest-neighbor withnections\n",
        "-  Faster to train\n",
        "-  Less expressive\n",
        "\n",
        "---\n",
        "\n",
        "##  How to use the Notesbook\n",
        "\n",
        "### MODE 1: Single Configuration Training\n",
        "\n",
        "1. **Chooif the withfiguration** by modifying the CONFIG dictionary:\n",
        "```python\n",
        "CONFIG = {\n",
        "    'encoding': 'angle',  # or 'amplitude'\n",
        "    'circuit_type': 'strongly_entangling',  # or 'basic_entangling'\n",
        "    'n_qubits': 8,\n",
        "    'n_layers': 3,\n",
        "}\n",
        "```\n",
        "\n",
        "2. **Run all cells** up to the ifction \"Comparative Analysis\"\n",
        "\n",
        "3. **Results**: one trained model in ~10-20 minuti\n",
        "\n",
        "### MODE 2: Automatic Comparison (4 withfigurations)\n",
        "\n",
        "1. **Run ALL cells** including the ifction \"Comparative Analysis\"\n",
        "\n",
        "2. The notebook automatically trains:\n",
        "   - Angle + Strongly Entangling\n",
        "   - Angle + Basic Entangling\n",
        "   - Amplitude + Strongly Entangling\n",
        "   - Amplitude + Basic Entangling\n",
        "\n",
        "3. **Results**:\n",
        "   -  Comparative charts\n",
        "   -  Best withfiguration\n",
        "   -  Fastest withfiguration\n",
        "   -  CSV with all results\n",
        "   - Total time: ~10-20 minutes\n",
        "\n",
        "---\n",
        "\n",
        "##  What to Expect\n",
        "\n",
        "### Expected accuracy:\n",
        "- Angle encoding: ~60-70%\n",
        "- Amplitude encoding: ~65-75%\n",
        "\n",
        "### Training times (single withfiguration):\n",
        "- Per withfiguration: ~3-5 minutes\n",
        "- All 4: ~10-20 minutes\n",
        "\n",
        "### Output:\n",
        "-  Confusion matrix\n",
        "-  Classification report\n",
        "-  Example predictions visualizzate\n",
        "-  Model saved\n",
        "\n",
        "---\n",
        "\n",
        "##  When to Uif This Notesbook\n",
        "\n",
        "**Uif this notebook (PCA-baifd) if:**\n",
        "-  You want quick exforiments\n",
        "-  You have risorif computational limited\n",
        "-  You want understand i withcepts baif del quantum ML\n",
        "-  You are exploring different encoding types\n",
        "\n",
        "**Use the other notebook (CNN-baifd) if:**\n",
        "-  You want maximum accuracy\n",
        "-  You have GPU available\n",
        "-  You want features appreif automatically\n",
        "\n",
        "---\n",
        "\n",
        "##  Dataset: EuroSAT\n",
        "\n",
        "**10 classes di land uif:**\n",
        "1. AnnualCrop - Annual crops\n",
        "2. Forest - Forests\n",
        "3. HerbaceousVegetation - Herbaceous vegetation\n",
        "4. Highway - Highways\n",
        "5. Industrial - Industrial areas\n",
        "6. Pasture - Pastures\n",
        "7. PermanentCrop - Permanent crops\n",
        "8. Residential - Residential areas\n",
        "9. River - Rivers\n",
        "10. SeaLake - Sea/Lakes\n",
        "\n",
        "**Characteristics:**\n",
        "- 27,000 total images\n",
        "- Resolution: 64×64 pixels\n",
        "- RGB (3 canali)\n",
        "- Satellite: Sentinel-2\n",
        "\n",
        "---\n",
        "\n",
        "##  Important Notess\n",
        "\n",
        "1. **Automatic download**: The dataset is downloaded automatically (~90 MB)\n",
        "2. **PCA**: Reduces 12,288 pixels (64×64×3) a 8 or 256 features\n",
        "3. **Quantum Circuit**: Uses PennyLane with local simulator\n",
        "4. **Training**: PyTorch Lightning with automatic early stopping\n",
        "5. **Reproducibility**: Fixed seed (42) for withsistent results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4LIZ4XqYeBP"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install pennylane pytorch-lightning torchvision scikit-learn matplotlib tqdm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cr6Oa0KYeBQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "import warnings\n",
        "import urllib3\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be4lKvSuYeBQ"
      },
      "source": [
        "## Configuration\n",
        "Set the hyforparameters and chooif encoding/circuit type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdbE0AKvYeBQ"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    'n_qubits': 8,  # Number of qubits (PCA will reduce to this dimension)\n",
        "    'n_layers': 3,  # Number of variational layers in the quantum circuit\n",
        "    'encoding': 'angle',  # Options: 'angle' or 'amplitude'\n",
        "    'circuit_type': 'strongly_entangling',  # Options: 'strongly_entangling' or 'basic_entangling'\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.001,\n",
        "    'max_epochs': 5,\n",
        "    'n_classes': 10,  # EuroSAT has 10 clasifs\n",
        "    'pca_components': 8,  # Must match n_qubits for angle encoding, or 2^n_qubits for amplitude\n",
        "}\n",
        "\n",
        "# Adjust PCA components baifd on encoding type\n",
        "if CONFIG['encoding'] == 'amplitude':\n",
        "    CONFIG['pca_components'] = 2 ** CONFIG['n_qubits']  # Amplitude encoding needs 2^n features\n",
        "else:\n",
        "    CONFIG['pca_components'] = CONFIG['n_qubits']  # Angle encoding needs n features\n",
        "\n",
        "print(f\"Configuration: {CONFIG}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_iqB01iYeBQ"
      },
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "Download EuroSAT dataift and apply PCA for dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INgyctuNYeBR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import urllib3\n",
        "\n",
        "def download_eurosat():\n",
        "    url = \"https://madm.dfki.de/files/sentinel/EuroSAT.zip\"\n",
        "    zip_path = \"EuroSAT.zip\"\n",
        "    target_dir = \"EuroSAT/2750\"\n",
        "\n",
        "    if not os.path.exists(target_dir):\n",
        "        print(\"Downloading EuroSAT RGB dataset...\")\n",
        "        response = requests.get(url, stream=True, verify=False)\n",
        "        total = int(response.headers.get('content-length', 0))\n",
        "        with open(zip_path, 'wb') as f:\n",
        "            downloaded = 0\n",
        "            for data in response.iter_content(chunk_size=8192):\n",
        "                f.write(data)\n",
        "                downloaded += len(data)\n",
        "                done = int(50 * downloaded / total)\n",
        "                print(f\"\\r[{'=' * done}{' ' * (50 - done)}] {downloaded/1e6:.1f}/{total/1e6:.1f} MB\", end='')\n",
        "        print(\"\\n Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"EuroSAT\")\n",
        "        os.remove(zip_path)\n",
        "        print(\"Dataset downloaded and extracted successfully!\")\n",
        "    else:\n",
        "        print(\"Dataset already available.\")\n",
        "\n",
        "def load_images(data_dir=\"EuroSAT/2750\", max_per_class=300):\n",
        "    images, labels, classes = [], [], []\n",
        "    for class_dir in sorted(Path(data_dir).iterdir()):\n",
        "        if class_dir.is_dir():\n",
        "            cls = class_dir.name\n",
        "            classes.append(cls)\n",
        "            files = list(class_dir.glob(\"*.jpg\"))[:max_per_class]\n",
        "            for f in files:\n",
        "                img = np.array(Image.open(f))\n",
        "                images.append(img)\n",
        "                labels.append(cls)\n",
        "    return np.array(images), np.array(labels), classes\n",
        "\n",
        "# Run download + load\n",
        "download_eurosat()\n",
        "images_raw, labels_raw, class_names = load_images(max_per_class=300)\n",
        "print(f\"Loaded {len(images_raw)} images from {len(class_names)} classes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cao4GeDHYeBR"
      },
      "outputs": [],
      "source": [
        "# Create label mapping\n",
        "label_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "labels_numeric = np.array([label_to_idx[label] for label in labels_raw])\n",
        "\n",
        "print(f\"Label mapping: {label_to_idx}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "\n",
        "# Update withfig with correct number of clasifs\n",
        "CONFIG['n_classes'] = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpGxVHFGYeBR"
      },
      "outputs": [],
      "source": [
        "# Visualize some samples\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(10):\n",
        "    idx = np.random.randint(len(images_raw))\n",
        "    axes[i].imshow(images_raw[idx])\n",
        "    axes[i].set_title(f\"{labels_raw[idx]}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Sample Images from EuroSAT Dataset', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjOL7mDbYeBR"
      },
      "outputs": [],
      "source": [
        "# Prepare data for PCA by flattening and normalizing images\n",
        "def prepare_data_for_pca(images, labels, max_samples=5000):\n",
        "    \"\"\"\n",
        "    Flatten and normalize images for PCA.\n",
        "    Uif a subift for efficiency in PCA fitting.\n",
        "    \"\"\"\n",
        "    # Uif subift for PCA fitting to save memory\n",
        "    indices = np.random.choice(len(images), min(max_samples, len(images)), replace=False)\n",
        "\n",
        "    features = []\n",
        "    iflected_labels = []\n",
        "\n",
        "    for idx in indices:\n",
        "        # Normalize image to [0, 1]\n",
        "        img = images[idx].astype(np.float32) / 255.0\n",
        "        # Flatten the image: (H, W, C) -> (H*W*C,)\n",
        "        features.append(img.flatten())\n",
        "        iflected_labels.append(labels[idx])\n",
        "\n",
        "    return np.array(features), np.array(iflected_labels)\n",
        "\n",
        "print(\"Preparing data for PCA...\")\n",
        "X_pca, y_pca = prepare_data_for_pca(images_raw, labels_numeric)\n",
        "print(f\"Feature shape before PCA: {X_pca.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2lOv8daYeBR"
      },
      "outputs": [],
      "source": [
        "# Fit PCA and scaler\n",
        "print(f\"\\nFitting PCA with {CONFIG['pca_components']} components...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_pca)\n",
        "\n",
        "pca = PCA(n_components=CONFIG['pca_components'])\n",
        "X_pca_reduced = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Feature shape after PCA: {X_pca_reduced.shape}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRp7F73yYeBS"
      },
      "outputs": [],
      "source": [
        "# Create custom dataift that applies PCA transformation\n",
        "class PCATransformedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset wrapfor that applies PCA transformation to images.\n",
        "    \"\"\"\n",
        "    def __init__(self, images, labels, pca, scaler):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.pca = pca\n",
        "        self.scaler = scaler\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # Get image and normalize\n",
        "      img = self.images[idx].astype(np.float32) / 255.0\n",
        "      label = self.labels[idx]\n",
        "\n",
        "      # Flatten and apply PCA\n",
        "      img_flat = img.flatten().reshape(1, -1)\n",
        "      img_scaled = self.scaler.transform(img_flat)\n",
        "      img_pca = self.pca.transform(img_scaled)\n",
        "\n",
        "      return torch.tensor(img_pca[0], dtype=torch.float32), int(label)\n",
        "\n",
        "# Create PCA-transformed dataift\n",
        "pca_dataift = PCATransformedDataset(images_raw, labels_numeric, pca, scaler)\n",
        "\n",
        "# Split into train, validation, and test ifts\n",
        "train_size = int(0.7 * len(pca_dataift))\n",
        "val_size = int(0.15 * len(pca_dataift))\n",
        "test_size = len(pca_dataift) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    pca_dataift, [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset splits:\")\n",
        "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1OD9NtzYeBS"
      },
      "source": [
        "## Quantum Circuit Definition\n",
        "\n",
        "Define the quantum circuits with different encoding and entangling strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg5baquYYeBS"
      },
      "outputs": [],
      "source": [
        "# Initialize quantum device\n",
        "dev = qml.device('default.qubit', wires=CONFIG['n_qubits'])\n",
        "\n",
        "# Define quantum circuit with angle encoding\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def quantum_circuit_angle_encoding(inputs, weights):\n",
        "    \"\"\"\n",
        "    Quantum circuit with angle encoding.\n",
        "    Each feature is encoded as a rotation angle on each qubit.\n",
        "    \"\"\"\n",
        "    # Angle encoding: encode each feature as RY rotation\n",
        "    for i in range(CONFIG['n_qubits']):\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "\n",
        "    # Variational layers\n",
        "    if CONFIG['circuit_type'] == 'strongly_entangling':\n",
        "        # Strongly entangling layers with full withnectivity\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(CONFIG['n_qubits']))\n",
        "    else:\n",
        "        # Basic entangling layers with nearest-neighbor withnectivity\n",
        "        qml.BasicEntanglerLayers(weights, wires=range(CONFIG['n_qubits']))\n",
        "\n",
        "    # Measurement: return expectation values for all qubits\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(CONFIG['n_qubits'])]\n",
        "\n",
        "\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def quantum_circuit_amplitude_encoding(inputs, weights):\n",
        "    \"\"\"\n",
        "    Quantum circuit with amplitude encoding.\n",
        "    Features are encoded as amplitudes of the quantum state.\n",
        "    Requires 2^n_qubits features (normalized).\n",
        "    \"\"\"\n",
        "    # Amplitude encoding: encode features as quantum state amplitudes\n",
        "    # Normalize inputs to unit vector\n",
        "    inputs_normalized = inputs / torch.sqrt(torch.sum(inputs**2) + 1e-8)\n",
        "    qml.AmplitudeEmbedding(features=inputs_normalized, wires=range(CONFIG['n_qubits']), normalize=True)\n",
        "\n",
        "    # Variational layers\n",
        "    if CONFIG['circuit_type'] == 'strongly_entangling':\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(CONFIG['n_qubits']))\n",
        "    else:\n",
        "        qml.BasicEntanglerLayers(weights, wires=range(CONFIG['n_qubits']))\n",
        "\n",
        "    # Measurement\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(CONFIG['n_qubits'])]\n",
        "\n",
        "\n",
        "# Select the appropriate circuit baifd on withfiguration\n",
        "quantum_circuit = quantum_circuit_angle_encoding if CONFIG['encoding'] == 'angle' else quantum_circuit_amplitude_encoding\n",
        "\n",
        "print(f\"Using {CONFIG['encoding']} encoding with {CONFIG['circuit_type']} circuit\")\n",
        "print(f\"Circuit outputs: {CONFIG['n_qubits']} expectation values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BmW1Lc-YeBS"
      },
      "outputs": [],
      "source": [
        "# Visualize the quantum circuit\n",
        "print(\"\\nQuantum Circuit Diagram:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create dummy inputs and weights for visualization\n",
        "dummy_input = torch.randn(CONFIG['pca_components'])\n",
        "\n",
        "if CONFIG['circuit_type'] == 'strongly_entangling':\n",
        "    # StronglyEntanglingLayers shape: (n_layers, n_qubits, 3)\n",
        "    dummy_weights = torch.randn(CONFIG['n_layers'], CONFIG['n_qubits'], 3)\n",
        "else:\n",
        "    # BasicEntanglerLayers shape: (n_layers, n_qubits)\n",
        "    dummy_weights = torch.randn(CONFIG['n_layers'], CONFIG['n_qubits'])\n",
        "\n",
        "print(qml.draw(quantum_circuit)(dummy_input, dummy_weights))\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrWfAFovYeBS"
      },
      "source": [
        "## Quantum Model Definition with PyTorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2go9jNLYeBS"
      },
      "outputs": [],
      "source": [
        "class QuantumClassifier(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Fully quantum classifier using PennyLane quantum circuit.\n",
        "    The model withsists of:\n",
        "    1. Quantum circuit for feature transformation\n",
        "    2. Classical linear layer for final classification\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Initialize quantum weights\n",
        "        if config['circuit_type'] == 'strongly_entangling':\n",
        "            # StronglyEntanglingLayers: (n_layers, n_qubits, 3)\n",
        "            weight_shape = (config['n_layers'], config['n_qubits'], 3)\n",
        "        else:\n",
        "            # BasicEntanglerLayers: (n_layers, n_qubits)\n",
        "            weight_shape = (config['n_layers'], config['n_qubits'])\n",
        "\n",
        "        # Quantum circuit weights (trainable parameters)\n",
        "        self.q_weights = nn.Parameter(torch.randn(weight_shape) * 0.1)\n",
        "\n",
        "        # Classical output layer to map quantum measurements to class probabilities\n",
        "        self.fc = nn.Linear(config['n_qubits'], config['n_classes'])\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Metrics\n",
        "        self.train_acc = []\n",
        "        self.val_acc = []\n",
        "\n",
        "    def forward(self, x):\n",
        "      \"\"\"\n",
        "      Forward pass through quantum circuit and classical layer.\n",
        "      \"\"\"\n",
        "      x = x.float()  # Force float32\n",
        "      batch_size = x.shape[0]\n",
        "\n",
        "      # Process each sample through quantum circuit\n",
        "      quantum_outputs = []\n",
        "      for i in range(batch_size):\n",
        "          q_out = quantum_circuit(x[i].float(), self.q_weights)\n",
        "          quantum_outputs.append(torch.stack(q_out))\n",
        "\n",
        "      quantum_outputs = torch.stack(quantum_outputs).float()\n",
        "      logits = self.fc(quantum_outputs)\n",
        "\n",
        "      return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_acc', acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configure optimizer for training.\n",
        "        Using Adam optimizer with configure_optimizers learning rate.\n",
        "        \"\"\"\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.config['learning_rate'])\n",
        "        # Optional: learning rate scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=5\n",
        "        )\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': scheduler,\n",
        "            'monitor': 'val_loss'\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFMLJl7XYeBS"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkT-2-BsYeBS"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COKkzfLpYeBT"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model = QuantumClassifier(CONFIG)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXhsL3b8YeBT"
      },
      "outputs": [],
      "source": [
        "# Setup callbacks\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='./checkpoints',\n",
        "    filename='quantum-classifier-{epoch:02d}-{val_acc:.4f}',\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_top_k=3\n",
        ")\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    mode='min',\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=CONFIG['max_epochs'],\n",
        "    callbacks=[checkpoint_callback, early_stop_callback],\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    log_every_n_steps=10,\n",
        "    enable_progress_bar=True\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6tbRwUfYeBT"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz8H_Pk5YeBT"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*50)\n",
        "trainer.fit(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFUuzgFkYeBT"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1CyQk9yYeBT"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "print(\"\\nEvaluating on test ift...\")\n",
        "test_results = trainer.test(model, test_loader)\n",
        "print(f\"\\nTest Results: {test_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsn_4YmXYeBT"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "# Detailed predictions on test set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader):\n",
        "        x, y = batch\n",
        "        logits = model(x)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckq8ofERYeBT"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80H-k8btYeBT"
      },
      "source": [
        "## Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek1Cg-e3YeBT"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(dataset, model, pca, scaler, images_raw, labels_numeric, num_samples=8):\n",
        "    \"\"\"\n",
        "    Visualize original images with predictions.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    model.eval()\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, ax in zip(indices, axes):\n",
        "            # Get original image from raw data\n",
        "            real_idx = dataset.indices[idx]\n",
        "            img_raw = images_raw[real_idx]\n",
        "            label = labels_numeric[real_idx]\n",
        "\n",
        "            # Get PCA features\n",
        "            img = img_raw.astype(np.float32) / 255.0\n",
        "            img_flat = img.flatten().reshape(1, -1)\n",
        "            img_scaled = scaler.transform(img_flat)\n",
        "            img_pca = pca.transform(img_scaled)\n",
        "            img_pca_tensor = torch.tensor(img_pca[0], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            # Predict\n",
        "            logits = model(img_pca_tensor)\n",
        "            pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "            # Display\n",
        "            ax.imshow(img_raw)\n",
        "            ax.set_title(f'True: {label}, Pred: {pred}',\n",
        "                        color='green' if pred == label else 'red')\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(test_dataset, model, pca, scaler, images_raw, labels_numeric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaT0K8ZbYeBT"
      },
      "source": [
        "##  Comparative Analysis: Different Encodings and Circuits\n",
        "\n",
        "This ifction automatically trains and compares all combinations of:\n",
        "- **Encodings**: Angle vs Amplitude\n",
        "- **Circuits**: Strongly Entangling vs Basic Entangling\n",
        "\n",
        "Total: 4 different withfigurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GCAL5DfYeBT"
      },
      "outputs": [],
      "source": [
        "# Configuration for comparative exforiments\n",
        "COMPARISON_CONFIG = {\n",
        "    'n_qubits': 8,\n",
        "    'n_layers': 3,\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.01,\n",
        "    'max_epochs': 3,  # Reduced for faster comparison\n",
        "    'n_classes': CONFIG['n_classes'],\n",
        "}\n",
        "\n",
        "# All combinations to test\n",
        "encodings = ['angle', 'amplitude']\n",
        "circuit_types = ['strongly_entangling', 'basic_entangling']\n",
        "\n",
        "print(\"Will test all combinations:\")\n",
        "for enc in encodings:\n",
        "    for circ in circuit_types:\n",
        "        print(f\"  - {enc} encoding + {circ} circuit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeeYQyXkYeBT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Dictionary to store results\n",
        "comparison_results = []\n",
        "\n",
        "print(\"Starting comparative experiments...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for encoding in encodings:\n",
        "    for circuit_type in circuit_types:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Training: {encoding.upper()} encoding + {circuit_type.upper()} circuit\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        # Update configuration\n",
        "        exp_config = COMPARISON_CONFIG.copy()\n",
        "        exp_config['encoding'] = encoding\n",
        "        exp_config['circuit_type'] = circuit_type\n",
        "\n",
        "        # Adjust PCA components based on encoding\n",
        "        if encoding == 'amplitude':\n",
        "            exp_config['pca_components'] = 2 ** exp_config['n_qubits']\n",
        "        else:\n",
        "            exp_config['pca_components'] = exp_config['n_qubits']\n",
        "\n",
        "        # Re-fit PCA if needed\n",
        "        if exp_config['pca_components'] != pca.n_components_:\n",
        "            print(f\"Re-fitting PCA with {exp_config['pca_components']} components...\")\n",
        "            pca_temp = PCA(n_components=exp_config['pca_components'])\n",
        "            X_scaled = scaler.transform(X_pca)\n",
        "            pca_temp.fit(X_scaled)\n",
        "\n",
        "            # Create new dataset\n",
        "            pca_dataset_temp = PCATransformedDataset(images_raw, labels_numeric, pca_temp, scaler)\n",
        "            train_temp, val_temp, test_temp = random_split(\n",
        "                pca_dataset_temp, [train_size, val_size, test_size],\n",
        "                generator=torch.Generator().manual_seed(42)\n",
        "            )\n",
        "            train_loader_temp = DataLoader(train_temp, batch_size=exp_config['batch_size'], shuffle=True)\n",
        "            val_loader_temp = DataLoader(val_temp, batch_size=exp_config['batch_size'], shuffle=False)\n",
        "            test_loader_temp = DataLoader(test_temp, batch_size=exp_config['batch_size'], shuffle=False)\n",
        "        else:\n",
        "            train_loader_temp = train_loader\n",
        "            val_loader_temp = val_loader\n",
        "            test_loader_temp = test_loader\n",
        "\n",
        "        # Create quantum device and circuit for this configuration\n",
        "        dev_temp = qml.device('default.qubit', wires=exp_config['n_qubits'])\n",
        "\n",
        "        if encoding == 'angle':\n",
        "            @qml.qnode(dev_temp, interface='torch')\n",
        "            def qcircuit_temp(inputs, weights):\n",
        "                inputs = inputs.float()\n",
        "                for i in range(exp_config['n_qubits']):\n",
        "                    qml.RY(inputs[i], wires=i)\n",
        "                if circuit_type == 'strongly_entangling':\n",
        "                    qml.StronglyEntanglingLayers(weights, wires=range(exp_config['n_qubits']))\n",
        "                else:\n",
        "                    qml.BasicEntanglerLayers(weights, wires=range(exp_config['n_qubits']))\n",
        "                return [qml.expval(qml.PauliZ(i)) for i in range(exp_config['n_qubits'])]\n",
        "        else:\n",
        "            @qml.qnode(dev_temp, interface='torch')\n",
        "            def qcircuit_temp(inputs, weights):\n",
        "                inputs = inputs.float()\n",
        "                inputs_norm = inputs / torch.sqrt(torch.sum(inputs**2) + 1e-8)\n",
        "                qml.AmplitudeEmbedding(features=inputs_norm, wires=range(exp_config['n_qubits']), normalize=True)\n",
        "                if circuit_type == 'strongly_entangling':\n",
        "                    qml.StronglyEntanglingLayers(weights, wires=range(exp_config['n_qubits']))\n",
        "                else:\n",
        "                    qml.BasicEntanglerLayers(weights, wires=range(exp_config['n_qubits']))\n",
        "                return [qml.expval(qml.PauliZ(i)) for i in range(exp_config['n_qubits'])]\n",
        "\n",
        "        # Create a modified model class that uses the temporary circuit\n",
        "        class QuantumClassifierTemp(pl.LightningModule):\n",
        "            def __init__(self, config, quantum_circuit):\n",
        "                super().__init__()\n",
        "                self.config = config\n",
        "                self.qcircuit = quantum_circuit\n",
        "\n",
        "                if config['circuit_type'] == 'strongly_entangling':\n",
        "                    weight_shape = (config['n_layers'], config['n_qubits'], 3)\n",
        "                else:\n",
        "                    weight_shape = (config['n_layers'], config['n_qubits'])\n",
        "\n",
        "                self.q_weights = nn.Parameter(torch.randn(weight_shape) * 0.1)\n",
        "                self.fc = nn.Linear(config['n_qubits'], config['n_classes'])\n",
        "                self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = x.float()\n",
        "                batch_size = x.shape[0]\n",
        "                quantum_outputs = []\n",
        "                for i in range(batch_size):\n",
        "                    q_out = self.qcircuit(x[i].float(), self.q_weights)\n",
        "                    quantum_outputs.append(torch.stack(q_out))\n",
        "                quantum_outputs = torch.stack(quantum_outputs).float()\n",
        "                logits = self.fc(quantum_outputs)\n",
        "                return logits\n",
        "\n",
        "            def training_step(self, batch, batch_idx):\n",
        "                x, y = batch\n",
        "                logits = self(x)\n",
        "                loss = self.criterion(logits, y)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                acc = (preds == y).float().mean()\n",
        "                self.log('train_loss', loss, prog_bar=True)\n",
        "                self.log('train_acc', acc, prog_bar=True)\n",
        "                return loss\n",
        "\n",
        "            def validation_step(self, batch, batch_idx):\n",
        "                x, y = batch\n",
        "                logits = self(x)\n",
        "                loss = self.criterion(logits, y)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                acc = (preds == y).float().mean()\n",
        "                self.log('val_loss', loss, prog_bar=True)\n",
        "                self.log('val_acc', acc, prog_bar=True)\n",
        "                return loss\n",
        "\n",
        "            def test_step(self, batch, batch_idx):\n",
        "                x, y = batch\n",
        "                logits = self(x)\n",
        "                loss = self.criterion(logits, y)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                acc = (preds == y).float().mean()\n",
        "                self.log('test_loss', loss)\n",
        "                self.log('test_acc', acc)\n",
        "                return loss\n",
        "\n",
        "            def configure_optimizers(self):\n",
        "                optimizer = torch.optim.Adam(self.parameters(), lr=self.config['learning_rate'])\n",
        "                return optimizer\n",
        "\n",
        "        # Initialize model\n",
        "        model_temp = QuantumClassifierTemp(exp_config, qcircuit_temp)\n",
        "\n",
        "        # Setup trainer\n",
        "        checkpoint_callback_temp = ModelCheckpoint(\n",
        "            dirpath=f'./checkpoints_comparison',\n",
        "            filename=f'{encoding}-{circuit_type}-{{epoch:02d}}-{{val_acc:.4f}}',\n",
        "            monitor='val_acc',\n",
        "            mode='max',\n",
        "            save_top_k=1\n",
        "        )\n",
        "\n",
        "        trainer_temp = pl.Trainer(\n",
        "            max_epochs=exp_config['max_epochs'],\n",
        "            callbacks=[checkpoint_callback_temp],\n",
        "            accelerator='auto',\n",
        "            devices=1,\n",
        "            enable_progress_bar=True,\n",
        "            enable_model_summary=False,\n",
        "            logger=False\n",
        "        )\n",
        "\n",
        "        # Train and measure time\n",
        "        start_time = time.time()\n",
        "        trainer_temp.fit(model_temp, train_loader_temp, val_loader_temp)\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # Test\n",
        "        test_results = trainer_temp.test(model_temp, test_loader_temp, verbose=False)\n",
        "\n",
        "        # Store results\n",
        "        result = {\n",
        "            'encoding': encoding,\n",
        "            'circuit_type': circuit_type,\n",
        "            'test_accuracy': test_results[0]['test_acc'],\n",
        "            'test_loss': test_results[0]['test_loss'],\n",
        "            'training_time': training_time,\n",
        "            'n_parameters': sum(p.numel() for p in model_temp.parameters()),\n",
        "            'pca_components': exp_config['pca_components']\n",
        "        }\n",
        "        comparison_results.append(result)\n",
        "\n",
        "        print(f\"\\nCompleted: Test Accuracy = {result['test_accuracy']:.4f}, Time = {training_time:.1f}s\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"All experiments completed!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNTKDERrYeBU"
      },
      "outputs": [],
      "source": [
        "# Create comparison DataFrame\n",
        "df_results = pd.DataFrame(comparison_results)\n",
        "\n",
        "print(\"\\n COMPARISON RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(df_results.to_string(index=False))\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P3dlaPjYeBU"
      },
      "outputs": [],
      "source": [
        "# Visualization 1: Accuracy Comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Bar plot: Accuracy by configuration\n",
        "x_labels = [f\"{r['encoding']}\\n{r['circuit_type'][:6]}\" for r in comparison_results]\n",
        "accuracies = [r['test_accuracy'] for r in comparison_results]\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
        "\n",
        "axes[0].bar(x_labels, accuracies, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_ylabel('Test Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylim([0, 1])\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(accuracies):\n",
        "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
        "\n",
        "# Bar plot: Training time\n",
        "times = [r['training_time'] for r in comparison_results]\n",
        "axes[1].bar(x_labels, times, color=colors, alpha=0.7, edgecolor='black')\n",
        "axes[1].set_ylabel('Training Time (seconds)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Training Time Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(times):\n",
        "    axes[1].text(i, v + max(times)*0.02, f'{v:.1f}s', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSUNcFL_YeBU"
      },
      "outputs": [],
      "source": [
        "# Visualization 2: Grouped comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Group by encoding\n",
        "for encoding in encodings:\n",
        "    encoding_results = [r for r in comparison_results if r['encoding'] == encoding]\n",
        "    circuit_names = [r['circuit_type'] for r in encoding_results]\n",
        "    accs = [r['test_accuracy'] for r in encoding_results]\n",
        "\n",
        "    idx = 0 if encoding == 'angle' else 1\n",
        "    axes[0, idx].bar(circuit_names, accs, color=['#3498db', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
        "    axes[0, idx].set_title(f'{encoding.upper()} Encoding', fontsize=12, fontweight='bold')\n",
        "    axes[0, idx].set_ylabel('Test Accuracy')\n",
        "    axes[0, idx].set_ylim([0, 1])\n",
        "    axes[0, idx].grid(axis='y', alpha=0.3)\n",
        "    for i, v in enumerate(accs):\n",
        "        axes[0, idx].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
        "\n",
        "# Group by circuit type\n",
        "for circuit in circuit_types:\n",
        "    circuit_results = [r for r in comparison_results if r['circuit_type'] == circuit]\n",
        "    encoding_names = [r['encoding'] for r in circuit_results]\n",
        "    accs = [r['test_accuracy'] for r in circuit_results]\n",
        "\n",
        "    idx = 0 if circuit == 'strongly_entangling' else 1\n",
        "    axes[1, idx].bar(encoding_names, accs, color=['#2ecc71', '#f39c12'], alpha=0.7, edgecolor='black')\n",
        "    axes[1, idx].set_title(f'{circuit.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
        "    axes[1, idx].set_ylabel('Test Accuracy')\n",
        "    axes[1, idx].set_ylim([0, 1])\n",
        "    axes[1, idx].grid(axis='y', alpha=0.3)\n",
        "    for i, v in enumerate(accs):\n",
        "        axes[1, idx].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.suptitle('Detailed Comparison Analysis', fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2O0vQLzYeBU"
      },
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"\\nSTATISTICAL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Best configuration\n",
        "best_result = max(comparison_results, key=lambda x: x['test_accuracy'])\n",
        "print(f\"\\nBEST CONFIGURATION:\")\n",
        "print(f\"   Encoding: {best_result['encoding'].upper()}\")\n",
        "print(f\"   Circuit: {best_result['circuit_type'].upper()}\")\n",
        "print(f\"   Test Accuracy: {best_result['test_accuracy']:.4f}\")\n",
        "print(f\"   Training Time: {best_result['training_time']:.1f}s\")\n",
        "\n",
        "# Fastest configuration\n",
        "fastest_result = min(comparison_results, key=lambda x: x['training_time'])\n",
        "print(f\"\\nFASTEST CONFIGURATION:\")\n",
        "print(f\"   Encoding: {fastest_result['encoding'].upper()}\")\n",
        "print(f\"   Circuit: {fastest_result['circuit_type'].upper()}\")\n",
        "print(f\"   Training Time: {fastest_result['training_time']:.1f}s\")\n",
        "print(f\"   Test Accuracy: {fastest_result['test_accuracy']:.4f}\")\n",
        "\n",
        "# Encoding comparison\n",
        "print(f\"\\nENCODING COMPARISON:\")\n",
        "for encoding in encodings:\n",
        "    enc_results = [r for r in comparison_results if r['encoding'] == encoding]\n",
        "    avg_acc = np.mean([r['test_accuracy'] for r in enc_results])\n",
        "    avg_time = np.mean([r['training_time'] for r in enc_results])\n",
        "    print(f\"   {encoding.upper()}: Avg Accuracy = {avg_acc:.4f}, Avg Time = {avg_time:.1f}s\")\n",
        "\n",
        "# Circuit comparison\n",
        "print(f\"\\nCIRCUIT COMPARISON:\")\n",
        "for circuit in circuit_types:\n",
        "    circ_results = [r for r in comparison_results if r['circuit_type'] == circuit]\n",
        "    avg_acc = np.mean([r['test_accuracy'] for r in circ_results])\n",
        "    avg_time = np.mean([r['training_time'] for r in circ_results])\n",
        "    print(f\"   {circuit.upper()}: Avg Accuracy = {avg_acc:.4f}, Avg Time = {avg_time:.1f}s\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIUxbauZYeBU"
      },
      "outputs": [],
      "source": [
        "# Save comparison results\n",
        "df_results.to_csv('/mnt/uifr-data/outputs/pca_comparison_results.csv', index=False)\n",
        "print(\"\\n Comparison results saved to: pca_comparison_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfHZ53X9YeBU"
      },
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "This notebook demonstrated:\n",
        "1.  PCA-baifd dimensionality reduction for quantum-compatible data\n",
        "2.  Angle encoding and amplitude encoding options\n",
        "3.  Strongly entangling vs basic entangling circuits\n",
        "4.  Full quantum variational classifier with PyTorch Lightning\n",
        "\n",
        "**Next Steps:**\n",
        "- Try different numbers of qubits and layers\n",
        "- Exforiment with different circuit architectures\n",
        "- Compare forformance between encoding methods\n",
        "- Try hybrid quantum-classical approaches (ife next notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwD82OiwYeBY"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'withfig': CONFIG,\n",
        "    'pca': pca,\n",
        "    'scaler': scaler\n",
        "}, 'quantum_classifier_pca.pth')\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzXntWh2jdY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}