<!-- .slide: data-background="#ffffffff" -->

<section data-transition="none">

### w7.1 How to interpret a quantum circuit as a model <!-- .element: class="r-fit-text" -->

- [w7.1.1] Deterministic quantum models
- [w7.1.2] Probabilistic quantum models
- [w7.1.3] Example 1 - VQC
- [w7.1.4] Example 2 - VG

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.1 - Deterministic quantum models (1) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

In order to interpret a variational quantum circuit as a deterministic machine learning model, we apply a quantum circuit $U(x, \theta)$ that depends on both the input $x$ and the parameters $\theta$ to the initial state $|0\rangle=|0...0\rangle$, and interpret the expectation of a measurement as the output of the model.

**Definition 5.1 (Deterministic quantum model)**

Let $\mathcal{X}$ be a data input domain, and let $U(x, \theta)$ with $x \in \mathcal{X}$, $\theta \in \mathbb{R}^K$ be a quantum circuit that depends on inputs and parameters, and $M$ a Hermitian operator representing a quantum observable. 

We denote by $|\psi(x, \theta)\rangle$ the state prepared by $U(x, \theta)|0\rangle$. 

</div>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.1 - Deterministic quantum models (2) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">
The function

$$f_\theta(x) = \langle\psi(x, \theta)|M|\psi(x, \theta)\rangle$$

or equivalently in density matrix notation,

$$f_\theta(x) = \text{tr}\{M\rho(x, \theta)\}$$

with $\rho(x, \theta) = U(x, \theta)^\dagger|0\rangle\langle 0|U(x, \theta)$, defines a **deterministic variational quantum model**.

</div>


</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.1 - Deterministic quantum models (3) <!-- .element: class="r-fit-text" -->

**Popular circuit structure:**

$$U(x, \theta) = W(\theta)S(x)$$

<img src="{{asset_folder}}/param_qc.png" style="width: 78%; border-radius: 10px;">

where:
- $S(x)$: Data embedding block (encodes classical data into quantum state)
- $W(\theta)$: Variational circuit (contains trainable parameters)

<div style="text-align: justify;">

This separation allows for a clear distinction between data encoding and parameter optimization. Both blocks can be decomposed into elementary quantum gates.

</div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.1 - Deterministic quantum models (4) <!-- .element: class="r-fit-text" -->

<img src="{{asset_folder}}/param_qc_dec.png" style="width: 78%; border-radius: 10px;">

**Detailed decomposition:**

$$S(x) = T_{N+1} \prod_{i=1}^{N} S_i(x_i)T_i,\ W(\theta) = V_{K+1} \prod_{k=1}^{K} W_k(\theta_k)V_k$$

where feature-encoding gates have form $S_i(x_i) = e^{-ix_iG_i}$, parameter-encoding gates are $W_k(\theta_k) = e^{-i\theta_kG_k}$, and $T_i$, $V_k$ are fixed unitaries.

<div style="text-align: justify;">

Here $G_i$ and $G_k$ are Hermitian operators (generators) that determine the structure of the gates. This form is fundamental for analyzing expressivity and trainability.

</div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.1 - Deterministic quantum models (5) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

When the measurement operator is written in its diagonal basis $M = \sum_i \mu_i|\mu_i\rangle\langle\mu_i|$, the model output becomes a weighted sum of measurement probabilities:

</div>

$$f_\theta(x) = \sum_i \mu_i |\langle\mu_i|\psi(x,\theta)\rangle|^2 = \sum_i \mu_i p(\mu_i)$$

where $p(\mu_i) = |\langle\mu_i|\psi(x,\theta)\rangle|^2$ is the probability of measuring outcome $\mu_i$.

**Example:** For Pauli-Z measurement $M = \sigma_z$ on a single qubit:

$$f_\theta(x) = p(0) - p(1)$$

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.1 - Deterministic quantum models (6) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

In practice, the expectation value must be estimated by performing $S$ measurements, each sampling an eigenvalue $\mu^{(s)} \in \{\mu_i\}$:

</div>

$$\hat{f}(x) = \frac{1}{S}\sum_{s=1}^{S} \mu^{(s)}$$

<div style="text-align: justify;">

The number of measurements scales as $O(\epsilon^{-2})$ to achieve estimation error $\epsilon$. Since measurement collapses the quantum state, the entire circuit must be rerun $S$ times.

</div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.2 - Probabilistic quantum models (1) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

<p>
Due to the inherent nature of quantum theory as a probabilistic framework, a similar template to the above can also serve to implement probabilistic quantum models. 
</p>
<p>
Let us first look at supervised models defined by a conditional probability $p_{\theta}(y|x)$ over the outputs given the inputs (see Fig. 5.3 left). For this we can associate the predictions in Y with the eigenvalues of the measurement operator, so that a measurement samples outputs y.
</p>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.2 - Probabilistic quantum models (2) <!-- .element: class="r-fit-text" -->

**Definition (Supervised probabilistic quantum model)**

<div style="text-align: justify;">

Let $\mathcal{X}$ be input and $\mathcal{Y}$ output domain, $U(x,\theta)$ input/parameter-dependent unitary with $|\psi(x,\theta)\rangle = U(x,\theta)|0\rangle$. 

Associate each measurement outcome with a possible output:

</div>

$$M = \sum_{y \in \mathcal{Y}} y|y\rangle\langle y|$$

The supervised probabilistic quantum model for a conditional distribution is defined by:

$$p_\theta(y|x) = |\langle y|\psi(x,\theta)\rangle|^2$$

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.2 - Probabilistic quantum models (3) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

The probabilities automatically sum to one since $\{|y\rangle\}$ forms a complete orthonormal basis: $\sum_{y \in \mathcal{Y}} |y\rangle\langle y| =$ &#120793;

</div>

**Binary classification example:**

Associate labels with Pauli-Z measurement outcomes:
- $y = -1$ corresponds to eigenvalue $-1$ (projector $|0\rangle\langle 0|$)
- $y = 1$ corresponds to eigenvalue $+1$ (projector $|1\rangle\langle 1|$)

**Multi-class classification:**

For $D = 2^n$ classes, use computational basis states $|d\rangle$, $d = 0,\ldots,D-1$ of $n$ qubits.

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.2 - Probabilistic quantum models (4) <!-- .element: class="r-fit-text" -->

**Definition (Unsupervised probabilistic quantum model)**

<div style="text-align: justify;">

For generative modeling, the circuit depends only on parameters (no input encoding). Let $W(\theta)$ be a unitary with $|\psi(\theta)\rangle = W(\theta)|0\rangle$ and measurement:

</div>

$$M = \sum_{x \in \mathcal{X}} x|x\rangle\langle x|$$

The unsupervised probabilistic quantum model (also called a **Born machine**):

$$p_\theta(x) = |\langle x|\psi(\theta)\rangle|^2$$

<div style="text-align: justify;">

This model naturally generates samples when implemented on a quantum computer. The name "Born machine" refers to Born's rule linking quantum states to probabilities, and to the classical Boltzmann machine architecture.

</div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.3 - Example 1: VQC (1) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

To illustrate how variational circuits work as models, we explicitly compute the model function for a simple single-qubit classifier. This example reveals the mathematical structure underlying quantum models.

</div>

<img src="{{asset_folder}}/simple_vqc.png" style="width: 78%; border-radius: 10px;">

**Circuit components:**
1. Pauli-X rotation $R_x(x)$ to encode scalar input $x \in \mathbb{R}$
2. General single-qubit rotation $\text{Rot}(\theta_1, \theta_2, \theta_3) = R_z(\theta_1)R_y(\theta_2)R_z(\theta_3)$
3. Pauli-Z measurement $\sigma_z$

Full circuit: $U(x,\theta) = \text{Rot}(\theta_1, \theta_2, \theta_3)R_x(x)$

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.3 - Example 1: VQC (2) <!-- .element: class="r-fit-text" -->

**Step 1 - Data encoding:**

<div style="text-align: justify;">

The Pauli-X rotation maps the classical input $x$ to a quantum state on the Bloch sphere:

</div>

$$|\phi(x)\rangle = R_x(x)|0\rangle = \begin{pmatrix} \cos\left(\frac{x}{2}\right) \\ -i\sin\left(\frac{x}{2}\right) \end{pmatrix}$$

**Step 2 - Apply parametrised rotation:**

$$|\psi(x,\theta)\rangle = \text{Rot}(\theta_1,\theta_2,\theta_3)|\phi(x)\rangle$$

<div style="text-align: justify;">

This rotation mixes the encoded information with trainable parameters.

</div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.3 - Example 1: VQC (3) <!-- .element: class="r-fit-text" -->

**Step 3 - Measurement:**

<div style="text-align: justify;">

After applying the parametrised rotation and computing the Pauli-Z expectation value (which can be done by hand or using computer algebra), we obtain:

</div>

$$f_\theta(x) = \langle\psi(x,\theta)|\sigma_z|\psi(x,\theta)\rangle$$

$$= \cos(\theta_2)\cos(x) - \sin(\theta_1)\sin(\theta_2)\sin(x)$$

<img src="{{asset_folder}}/simple_vqc_res.png" style="width: 78%; border-radius: 10px;">

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.4 - Example 2: VG (1) <!-- .element: class="r-fit-text" -->

<div style="text-align: justify;">

The second example demonstrates an unsupervised probabilistic model for generating simple images. This Born machine architecture is inspired by classical Boltzmann machines and shows how quantum circuits can learn probability distributions. Let's considere this architecture:

- **Visible layer:** 4 qubits encode $2 \times 2$ pixel images via basis encoding
- **Hidden layer:** 3 unmeasured qubits, to add computational power by increasing degrees of freedom

</div>

<img src="{{asset_folder}}/simple_vgc.png" style="width: 78%; border-radius: 10px;">

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.4 - Example 2: VG (2) <!-- .element: class="r-fit-text" -->

**Circuit and model:**

<div style="text-align: justify;">

Starting from the all-zero state $|0000000\rangle$, apply a variational unitary to all 7 qubits:

</div>

$$|\psi(\theta)\rangle = W(\theta)|0000000\rangle$$

The probabilistic model over 4-qubit visible configurations:

$$p_\theta(x) = |\langle x|\psi(\theta)\rangle|^2, \quad x \in \{0,1\}^{\otimes 4}$$

<div style="text-align: justify;">

Measurement produces four Pauli-Z eigenvalues, e.g., $(1,1,-1,-1) \to |0011\rangle \to$ image $(w,w,b,b)$.

</div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w7.1.4 - Example 2: VG (3) <!-- .element: class="r-fit-text" -->

**Optimal state:**

<div style="text-align: justify;">

For this toy dataset, we can construct the ideal state that assigns equal probability to all four bars-and-stripes patterns:

</div>

$$|\psi_{\text{opt}}\rangle = \frac{1}{2}(|1010\rangle + |0101\rangle + |1100\rangle + |0011\rangle)$$

<div style="text-align: justify;">

This gives probability $\frac{1}{4}$ for each pattern. The hidden qubits allow more complex entanglement structures while maintaining the same visible probabilities after tracing them out, similar to hidden units in restricted Boltzmann machines.

In practice, the model would learn to generate these patterns from training data without knowing the distribution in advance.

</div>

</section>