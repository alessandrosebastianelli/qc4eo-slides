<!-- .slide: data-background="#ffffffff" -->

<section data-transition="none">

### w2.3 - Generative Neural Networks

- [w2.3.1] Generative AI
- [w2.3.2] Types of Generative Models
- [w2.3.3] Variational Autoencoders (VAEs)
- [w2.3.4] Generative Adversarial Networks (GANs)
- [w2.3.5] Diffusion Models

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.3.1 - Generative AI <!-- .element: class="r-fit-text" -->
  <p style="text-align: justify;">
    <strong>Generative AI</strong> refers to models that <strong>learn to generate new data</strong> similar to the training set. The key idea is to learn a distribution $p_\theta(x)$ that allows generating realistic samples $x \sim p_\theta(x)$.
  </p>
  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 50%; max-width: 50%;text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        Common applications include:
      </p>
      <ul>
        <li>Image synthesis</li>
        <li>Text generation</li>
        <li>Audio synthesis and music generation</li>
        <li>Data augmentation</li>
      </ul>
    </div>
    <div style="flex: 0 0 50%; text-align: center;">
      <img 
        src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/Discriminative_vs_Generative_Neural_Networks.png/640px-Discriminative_vs_Generative_Neural_Networks.png" 
        style="width: 90%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://www.wikiwand.com/en/articles/Generative_artificial_intelligence)
      </p>
    </div>
  </div>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.3.2 - Types of Generative Models <!-- .element: class="r-fit-text" -->
  <div>
      <img 
        src="https://eevibes.com/wp-content/uploads/2025/07/Types-of-Generative-AI-Models-1.png" 
        style="width: 75%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://eevibes.com/computing/what-is-generative-ai/)
      </p>
  </div>
  <div style="text-align: justify;">
      <ul>
        <li><strong>Variational Autoencoders (VAEs):</strong> Encode input into latent space $z \sim q_\phi(z|x)$ and decode to reconstruct $\hat{x}$.</li>
        <li><strong>Generative Adversarial Networks (GANs):</strong> Train a generator $G(z)$ and discriminator $D(x)$ in an adversarial game:
        $$\min_G \max_D \mathbb{E}_{x \sim p_\text{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1-D(G(z)))]$$</li>
        <li><strong>Diffusion Models:</strong> Use iterative denoising process to generate realistic samples.</li>
      </ul>
  </div>

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.3.3 - Variational Autoencoders (VAEs) <!-- .element: class="r-fit-text" -->
  <p style="text-align: justify;">
    VAEs learn a probabilistic mapping from data $x$ to latent variables $z$.
  </p>
  <div style="flex: 0 0 50%; text-align: center;">
    <img 
      src="https://lilianweng.github.io/posts/2018-08-12-vae/autoencoder-architecture.png" 
      style="width: 90%; border-radius: 10px;">
    <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
      (image source: https://lilianweng.github.io/posts/2018-08-12-vae/)
    </p>
  </div>
  <p style="text-align: justify;">
    The model consists of:
  </p>
  <div style="text-align: justify;">
    <ul>
      <li><strong>Encoder:</strong> $q_\phi(z|x)$ maps input to latent distribution</li>
      <li><strong>Decoder:</strong> $p_\theta(x|z)$ reconstructs data from latent code</li>
    </ul>
  </div>
  <p style="text-align: justify;"><!-- ============================================================================ -->

<section data-transition="none">

### w2.3.7 - Applications of Generative Models <!-- .element: class="r-fit-text" -->

  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 50%; max-width: 50%;text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        Generative models are widely used for Earth Observation (EO) and general AI tasks:
      </p>
      <ul>
        <li><strong>VAEs:</strong> latent space exploration, data compression, synthetic data generation</li>
        <li><strong>GANs:</strong> high-resolution image synthesis, inpainting, super-resolution, anomaly detection</li>
        <li><strong>Diffusion Models:</strong> photorealistic image generation, super-resolution, multi-modal EO data synthesis</li>
      </ul>
      <p>
        <strong>Benefits:</strong> Mitigate data scarcity, improve robustness of predictive models, enable scenario simulation for rare events.
      </p>
    </div>
    <div style="flex: 0 0 50%; text-align: center;">
      <img 
        src="https://www.researchgate.net/publication/380439652/figure/fig1/AS:11431281255207946@1718720398346/Application-of-Generative-AI-in-Different-Sectors.png" 
        style="width: 90%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: ResearchGate DOI:10.1109/ACCESS.2024.3411606)
      </p>
    </div>
  </div>
</section>
    <strong> A common Loss function (Evidence Lower Bound):</strong>
  </p>
  <p>
    $$\mathcal{L}_{VAE} = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$$
  </p>
  <p style="text-align: justify;">
    This encourages reconstruction accuracy and latent regularization. The latent variable $z$ can be sampled to generate new data.
  </p>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.3.4 - Generative Adversarial Networks (GANs) <!-- .element: class="r-fit-text" -->
  <div style="text-align: justify;"style="text-align: justify;">
    <p>
      GANs consist of <strong>two networks</strong> trained in competition:
    </p>
    <ul>
      <li><strong>Generator $G(z)$:</strong> maps random noise $z \sim p_z$ to data space</li>
      <li><strong>Discriminator $D(x)$:</strong> distinguishes real from generated samples</li>
    </ul><!-- ============================================================================ -->

<section data-transition="none">

### w2.3.7 - Applications of Generative Models <!-- .element: class="r-fit-text" -->

  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 50%; max-width: 50%;text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        Generative models are widely used for Earth Observation (EO) and general AI tasks:
      </p>
      <ul>
        <li><strong>VAEs:</strong> latent space exploration, data compression, synthetic data generation</li>
        <li><strong>GANs:</strong> high-resolution image synthesis, inpainting, super-resolution, anomaly detection</li>
        <li><strong>Diffusion Models:</strong> photorealistic image generation, super-resolution, multi-modal EO data synthesis</li>
      </ul>
      <p>
        <strong>Benefits:</strong> Mitigate data scarcity, improve robustness of predictive models, enable scenario simulation for rare events.
      </p>
    </div>
    <div style="flex: 0 0 50%; text-align: center;">
      <img 
        src="https://www.researchgate.net/publication/380439652/figure/fig1/AS:11431281255207946@1718720398346/Application-of-Generative-AI-in-Different-Sectors.png" 
        style="width: 90%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: ResearchGate DOI:10.1109/ACCESS.2024.3411606)
      </p>
    </div>
  </div>
</section>
  </div>
  <div style="text-align: center;">
      <img 
        src="https://sthalles.github.io/assets/dcgan/GANs.png" 
        style="width: 90%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://medium.com/@ml_dl_explained/understanding-the-evidence-lower-bound-elbo-loss-in-variational-autoencoders-423fcf19d318)
      </p>
    </div>
    <div style="text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        <strong>Adversarial training objective:</strong>
      </p>
      <p>
        $$\min_G \max_D \mathbb{E}_{x \sim p_\text{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1-D(G(z)))]$$
      </p>
      <p>
        The generator improves by fooling the discriminator, while the discriminator improves by distinguishing real versus generated samples.
      </p>
    </div>
    
  </div>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.3.5 - Diffusion Models <!-- .element: class="r-fit-text" -->
  <p style="text-align: justify;">
    <strong>Diffusion Models</strong> generate data by <strong>reversing a gradual noising process</strong>.
  </p>
  <div>
      <img 
        src="https://media.geeksforgeeks.org/wp-content/uploads/20250804190118579985/diffusion_model.webp" 
        style="width: 70%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://www.geeksforgeeks.org/artificial-intelligence/what-are-diffusion-models/)
      </p>
  </div>
  <div style="text-align: justify;">
    <p>
      The process consists of two phases:
    </p>
    <p>
      <strong>Forward process:</strong> add noise to data over $T$ steps:
    </p>
    <p>
      $$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)$$
    </p>
    <p>
      <strong>Reverse process:</strong> learn $p_\theta(x_{t-1} | x_t)$ to denoise step by step:
    </p>
    <p>
      $$x_0 \sim p_\theta(x_0 | x_1, \dots, x_T)$$
    </p>
  </div>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.3.5 - Diffusion Models (2) <!-- .element: class="r-fit-text" -->

  <div style="text-align: justify;">
    <h3 class="r-fit-text"></h3>
    <p>
      <strong>Forward (noising) process:</strong>
    </p>
    <p>
      $$x_t = \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0,I)$$
    </p>
    <p>
      <strong>Reverse (denoising) process:</strong>
    </p>
    <p>
      Learn a neural network $\epsilon_\theta(x_t, t)$ to predict noise and recover $x_{t-1}$:
    </p>
    <p>
      $$x_{t-1} = \frac{1}{\sqrt{1-\beta_t}} \left(x_t - \beta_t \epsilon_\theta(x_t, t) \right) + \sigma_t z$$
    </p>
    <p>
      The model iteratively reconstructs $x_0$ from pure noise $x_T \sim \mathcal{N}(0, I)$, progressively removing noise to generate high-quality samples.
    </p>
  </div>
</section>