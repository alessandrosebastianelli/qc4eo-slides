<!-- .slide: data-background="#ffffffff" -->

<section data-transition="none">

### w2.1 - Convolutional Neural Networks

- [w2.1.1] Introduction to CNNs
- [w2.1.2] Convolution Operation
- [w2.1.3] Feature Maps and Channels
- [w2.1.4] Stride, Padding, and Output Size
- [w2.1.5] Pooling Layers

</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.1.1 - Convolutional Neural Networks <!-- .element: class="r-fit-text" -->
  <p style="text-align: justify;">
  Convolutional Neural Networks (CNNs) are specialized deep learning architectures designed to process spatial or grid-like data.
  </p>

  <div>
    <img 
      src="https://assets.skyfilabs.com/images/blog/image-classifer-for-identifying-cats-dogs.webp" 
      style="width: 95%; border-radius: 10px;">
    <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
      (image source: https://www.skyfilabs.com/project-ideas/image-classifier-for-identifying-cats-dogs)
    </p>
  </div>
  <p style="text-align: justify;">
  CNNs introduce three important ideas, improving ML systems: <strong>sparse interactions</strong>, <strong>parameter sharing</strong> and <strong>equivariant representations</strong>.
  </p>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.1.2 - Convolution Operation <!-- .element: class="r-fit-text" -->

  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 50%; max-width: 50%;text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        A <strong>convolutional layer</strong> applies a filter (kernel) that slides over the input to compute a feature map:
      </p>
      <p>
        $$y_{i,j}^{(k)} = \sum_{m} \sum_{n} x_{i+m,\,j+n} \, w_{m,n}^{(k)} + b^{(k)}$$
      </p>
      <p>
        Where $x$ is the input feature map, $w^{(k)}$ is the kernel for the $k$-th feature, $b^{(k)}$ is the bias term, and $y^{(k)}$ is the resulting feature map. 
      </p>
      <p>
        Each kernel learns to detect specific local patterns such as edges or textures.
      </p>
    </div>
    <div style="flex: 0 0 50%; text-align: center;">
      <img 
        src="https://miro.medium.com/v2/resize:fit:1400/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif" 
        style="width: 90%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: Medium - Convolution operation visualization)
      </p>
    </div>
  </div>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.1.3 - Feature Maps and Channels <!-- .element: class="r-fit-text" -->
  <p style="text-align: justify;">
  In images, especially in EO, each pixel has multiple <strong>channels</strong>. A CNN learns multiple <strong>feature maps</strong> across these channels to extract different patterns.
  </p>
  
  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 50%; max-width: 50%; text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        In a <strong>2D convolution</strong>, the kernel slides over the spatial dimensions (height and width), combining information across all channels at once.
      </p>
      <p>
        In contrast, a <strong>3D convolution</strong> extends the kernel over an additional dimension â€” such as <em>time</em> in temporal EO data or <em>spectral depth</em>. This allows the network to capture both spatial and inter-band or temporal correlations, making it more powerful for spatiotemporal or hyperspectral feature extraction.
      </p>
    </div>
    <div style="flex: 0 0 50%; text-align: center;">
      <img 
        src="https://ars.els-cdn.com/content/image/1-s2.0-S136481522200130X-gr1.jpg" 
        style="width: 99%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://doi.org/10.1016/j.envsoft.2022.105424)
      </p>
    </div>
  </div>
</section>


<!-- ============================================================================ -->

<section data-transition="none">

### w2.1.4 - Stride, Padding, and Output Size <!-- .element: class="r-fit-text" -->

  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 50%; max-width: 50%;text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        <strong>Stride ($s$)</strong> controls how far the filter moves at each step, and <strong>Padding ($p$)</strong> preserves spatial dimensions by adding borders around the input.
      </p>
      <p>
        The output size $(H_\text{out}, W_\text{out})$ is calculated as:
      </p>
      <p>
        $$H_\text{out} = \frac{H_\text{in} - K + 2p}{s} + 1$$
        $$W_\text{out} = \frac{W_\text{in} - K + 2p}{s} + 1$$
      </p>
      <p>
        Choosing $p = \frac{K-1}{2}$ yields "same convolution", keeping dimensions constant when $s=1$.
      </p>
    </div>
    <div style="flex: 0 0 50%; text-align: center;">
      <img 
        src="https://miro.medium.com/v2/resize:fit:1200/1*1VJDP6qDY9-ExTuQVEOlVg.gif" 
        style="width: 90%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://medium.com/geekculture/convolutional-neural-networks-ab4b24d1f916)
      </p>
    </div>
  </div>
</section>

<!-- ============================================================================ -->

<section data-transition="none">

### w2.1.5 - Pooling Layers <!-- .element: class="r-fit-text" -->

  <p style="text-align: justify;">
  <strong>Pooling layers</strong> reduce spatial dimensions while preserving key information, helping to control overfitting and provide translational invariance.
  </p>
  <div style="
    display: flex; 
    align-items: center; 
    justify-content: center; 
    gap: 5rem;
  ">
    <div style="flex: 0 0 40%; max-width: 50%;text-align: justify;">
      <h3 class="r-fit-text"></h3>
      <p>
        <strong>Max pooling:</strong>
        $$y_{i,j} = \max_{(m,n) \in R(i,j)} x_{m,n}$$
      </p>
      <p>
        <strong>Average pooling:</strong>
        $$y_{i,j} = \frac{1}{|R(i,j)|} \sum_{(m,n) \in R(i,j)} x_{m,n}$$
      </p>
    </div>
    <div style="flex: 0 0 60%; text-align: center;">
      <img 
        src="https://miro.medium.com/1*fXxDBsJ96FKEtMOa9vNgjA.gif" 
        style="width: 99%; border-radius: 10px;">
      <p style="font-size: 0.3em; color: #888; margin-top: 0.5em;">
        (image source: https://pub.towardsai.net/introduction-to-pooling-layers-in-cnn-dafe61eabe34?gi=dbceac8e5823)
      </p>
    </div>
  </div>
  <p style="text-align: justify;">
  Pooling reduces computational requirements and makes the network more robust to small translations in the input.
  </p>
</section>